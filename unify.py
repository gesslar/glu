#!/usr/bin/env python3
import os
import json
import argparse
from pathlib import Path

class GluUnifier:
    def __init__(self, project_root, output_file):
        self.project_root = Path(project_root)
        self.output_file = Path(output_file)
        self.scripts_config = None

    def load_scripts_config(self):
        """Load the scripts.json configuration file."""
        config_path = self.project_root / 'scripts.json'
        if not config_path.exists():
            raise FileNotFoundError(f"scripts.json not found in {self.project_root}")

        with open(config_path, 'r', encoding='utf-8') as f:
            self.scripts_config = json.load(f)

    def process_scripts(self):
        """Process all scripts in the order specified by scripts.json."""
        if not self.scripts_config:
            self.load_scripts_config()

        processed_content = []
        total_size = 0

        # Add a header comment
        header = f"-- Generated by GluUnifier\n"
        processed_content.append(header)

        # Process each script entry
        for script_entry in self.scripts_config:
            # Skip if not active
            if script_entry.get("isActive", "").lower() != "yes":
                print(f"Skipping inactive script: {script_entry['name']}")
                continue

            # Skip folders
            if script_entry.get("isFolder", "").lower() == "yes":
                print(f"Skipping folder: {script_entry['name']}")
                continue

            script_name = f"{script_entry['name']}.lua"
            script_path = self.project_root / script_name

            if not script_path.exists():
                print(f"Warning: Script not found: {script_path}")
                continue

            print(f"Processing: {script_name}")

            with open(script_path, 'r', encoding='utf-8') as f:
                content = f.read()
                total_size += len(content)

            # Add a comment to mark the start of each file
            processed_content.append(f"\n-- File: {script_name}")
            processed_content.append(content)

        # Add return statement at the end for single-file distribution usage
        processed_content.append("\n-- Return Glu for module usage")
        processed_content.append("return Glu")

        return '\n'.join(processed_content), total_size

    def build(self):
        """Build the unified output."""
        print(f"Unifying Glu from {self.project_root}")

        # Process all scripts
        content, original_size = self.process_scripts()

        # Create output directory if it doesn't exist
        self.output_file.parent.mkdir(parents=True, exist_ok=True)

        # Write the output
        with open(self.output_file, 'w', encoding='utf-8') as f:
            f.write(content)

        # Print build statistics
        print(f"\nUnification completed: {self.output_file}")
        print(f"Size: {original_size:,} bytes")

def main():
    parser = argparse.ArgumentParser(description='Unify Glu scripts into a single file')
    parser.add_argument('project_root', help='Root directory of the Glu project')
    parser.add_argument('output_file', help='Output file path')

    args = parser.parse_args()

    unifier = GluUnifier(
        project_root=args.project_root,
        output_file=args.output_file
    )

    unifier.build()

if __name__ == '__main__':
    main()
